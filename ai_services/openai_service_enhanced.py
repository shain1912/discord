import os
import asyncio
import discord
from dotenv import load_dotenv
from openai import AsyncOpenAI
import logging
from message_manager import message_manager

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("âš ï¸ OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë¹„ë™ê¸° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

async def get_gpt_response_streaming(bot, prompt: str, interaction) -> None:
    """í–¥ìƒëœ ìŠ¤íŠ¸ë¦¬ë° GPT ì‘ë‹µ (í ì‹œìŠ¤í…œ ì ìš©)"""
    if not openai_client:
        await message_manager.safe_followup_send(
            interaction, 
            "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", 
            ephemeral=True
        )
        return
    
    try:
        # í”„ë¡¬í”„íŠ¸ ìµœì í™”
        optimized_prompt = f\"\"\"
ë‹¤ìŒ ì§ˆë¬¸ì— ë„ì›€ì´ ë˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”. í•„ìš”í•˜ë‹¤ë©´ ì˜ˆì‹œë‚˜ ì„¤ëª…ë„ í¬í•¨í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {prompt}
        \"\"\"
        
        # OpenAI ìŠ¤íŠ¸ë¦¼ ìƒì„±
        stream = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ê³  ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìƒì„¸í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": optimized_prompt}
            ],
            max_tokens=1500,
            temperature=0.7,
            stream=True,
            timeout=30  # íƒ€ì„ì•„ì›ƒ ì—°ì¥
        )
        
        # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¥¼ ë©”ì‹œì§€ ë§¤ë‹ˆì €ì— ìœ„ì„
        async def content_generator():
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        
        await message_manager.streaming_response_handler(
            interaction, 
            content_generator(),
            "ğŸ¤– **ChatGPT ì‘ë‹µ:**\\n\\n"
        )
                
    except asyncio.TimeoutError:
        await message_manager.safe_followup_send(
            interaction,
            "â° ì‘ë‹µ ìƒì„± ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", 
            ephemeral=True
        )
    except Exception as e:
        logger.error(f"Streaming GPT error: {e}")
        await message_manager.safe_followup_send(
            interaction,
            "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 
            ephemeral=True
        )

# í ì‹œìŠ¤í…œ í†µí•©ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
async def queue_gpt_request(bot, prompt: str, interaction):
    """GPT ìš”ì²­ì„ íì— ì¶”ê°€"""
    from request_manager_enhanced import RequestType
    
    success = await bot.request_manager.queue_request(
        user_id=interaction.user.id,
        request_type=RequestType.CHAT,
        handler=get_gpt_response_streaming,
        bot=bot,
        prompt=prompt,
        interaction=interaction
    )
    
    if not success:
        await message_manager.safe_followup_send(
            interaction,
            "âš ï¸ ì„œë²„ê°€ ë°”ì©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            ephemeral=True
        )
